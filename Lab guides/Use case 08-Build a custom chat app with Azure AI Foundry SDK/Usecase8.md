Cas d'utilisation 08-Cr√©er une application de chat personnalis√©e avec le
SDK Azure AI Foundry

**Temps estim√© : 120 minutes**

## Objectif

L'objectif de ce laboratoire est de cr√©er, d'√©valuer et de d√©ployer un
agent bas√© sur la g√©n√©ration augment√©e par r√©cup√©ration (RAG) √† l'aide
du SDK Azure AI Foundry. Le laboratoire vous guide tout au long de la
configuration du projet et de l'environnement de d√©veloppement, du
d√©ploiement de mod√®les d'IA (par exemple, GPT-4 et
text-embedding-ada-002), de l'int√©gration d'Azure AI Search pour la
r√©cup√©ration de documents et de la cr√©ation d'une application de chat de
r√©cup√©ration des connaissances (RAG) personnalis√©e. L'accent est mis sur
l'ancrage des r√©ponses du mod√®le d'IA avec des donn√©es produit
pertinentes, le d√©veloppement d'une interface de chat personnalis√©e et
l'√©valuation des performances des r√©ponses g√©n√©r√©es.

## Solution

La solution implique la mise en place d'un projet dans Azure AI Foundry,
le d√©ploiement de mod√®les d'IA (GPT-4 et text-embedding-ada-002) et
l'int√©gration d'Azure AI Search pour stocker et r√©cup√©rer des donn√©es de
produit personnalis√©es. Il comprend la cr√©ation de scripts Python pour
g√©n√©rer des int√©grations vectorielles, cr√©er des index de recherche et
les interroger pour obtenir des informations pertinentes sur les
produits. Une interface de chat bas√©e sur RAG est d√©velopp√©e pour
fournir des r√©ponses fond√©es en exploitant les r√©sultats de recherche,
et les performances de l'application de chat sont √©valu√©es √† l'aide
d'ensembles de donn√©es et de mesures pr√©d√©finis pour am√©liorer son
efficacit√©.

## Exercice 0 : Comprendre la machine virtuelle et les informations d'identification

Dans cet exercice, nous allons identifier et comprendre les informations
d'identification que nous utiliserons tout au long du laboratoire.

**Important :** Passez en revue chaque √©tape de cet exercice pour
conna√Ætre les termes g√©n√©riques et les informations d'identification qui
seront utilis√©s pour l'ex√©cution du laboratoire.

1.  L'onglet **Instructions** contient le guide de laboratoire avec les
    instructions √† suivre tout au long du laboratoire.

2.  **L** 'onglet **Ressources** contient les informations
    d'identification n√©cessaires √† l'ex√©cution du laboratoire.

- **URL** ‚Äì URL du portail Azure

- **Subscription** ‚Äì Il s'agit de l**'ID** du **subscription** qui vous
  a √©t√© attribu√©

- **Username**: **User ID** avec lequel vous devez **login** aux **Azure
  services**.

- **Password-** **Password** pour la **Azure login**.

> Appelons ce nom d'utilisateur et ce mot de passe en taant qu‚Äô**Azure
> login credentials**. Nous utiliserons ces cr√©dits chaque fois que nous
> mentionnerons les **Azure¬†login credentials**

- **Resource Group** : **Resource Group** qui vous est attribu√©.

> **Important** : Veillez √† cr√©er toutes vos ressources sous ce Resource
> Group

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image1.png)

3.  L'onglet **Help** contient les informations d'assistance. La valeur
    **ID** ici est l'ID de **Lab instance ID** qui sera utilis√© lors de
    l'ex√©cution du laboratoire.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image2.png)

## Exercice 1 - Configurer un environnement de projet et de d√©veloppement pour cr√©er une application de r√©cup√©ration des connaissances (RAG) personnalis√©e avec le Kit de d√©veloppement logiciel (SDK) Azure AI Foundry

### T√¢che 1 : Cr√©er un projet

Pour cr√©er un projet dans Azure AI Foundry, proc√©dez comme suit :

1.  Connectez-vous √† Azure AI Foundry √† l'adresse
    +++<https://ai.azure.com/>+++ √† l'aide **d‚ÄôAzure login credentials**

> ![](./media/image3.png)

2.  S√©lectionnez **+ Create project**

> ![](./media/image4.png)

3.  Entrez +++**RAGproj\<Lab ID d'instance \>**+++ comme nom du projet,
    cliquez sur **Customize**

> **Remarque :** Remplacez l'**\< Lab instance ID \>** par votre **Lab
> instance ID**
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image5.png)

4.  Sur la page suivante, entrez les d√©tails suivants et cliquez sur
    **Next**

> Hub name : +++hub\<Lab instance ID\>+++
>
> Subscription: S√©lectionnez l'abonnement qui vous a √©t√© attribu√©
>
> Create new Resource Group : s√©lectionnez le Resource Group attribu√©
> (ResourceGroup1)
>
> Loaction : East US 2 or Sweden Central (nous avons utilis√© USA Est 2
> lors de l'ex√©cution de cet atelier)
>
> Laissez le reste par d√©faut et cliquez sur **Next**
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image6.png)

5.  Sur la page **Review and finish**, cliquez sur **Create.**

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image7.png)

6.  La cr√©ation de la ressource prendra quelques minutes.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image8.png)

7.  Fermez les windows contextuelles, le cas √©ch√©ant.

8.  √Ä partir de la page d'accueil du projet, notez **la Project
    connection string** dans un bloc-notes √† utiliser lors de la
    prochaine t√¢che de cet exercice.

> ![](./media/image9.png)

### T√¢che 2 : D√©ployer des mod√®les

Vous avez besoin de deux mod√®les pour cr√©er une application de
conversation bas√©e sur RAG : un mod√®le de conversation Azure OpenAI
(gpt-4o-mini) et un mod√®le d'incorporation Azure OpenAI
(text-embedding-ada-002). D√©ployez ces mod√®les dans votre projet Azure
AI Foundry, √† l'aide de cet ensemble d'√©tapes pour chaque mod√®le.

Les √©tapes suivantes d√©ploient un mod√®le sur un point de terminaison en
temps r√©el √† partir du catalogue de mod√®les du portail AI Foundry :

1.  Dans le volet de navigation de gauche, s√©lectionnez **Model
    catalog**

> ![](./media/image10.png)

2.  S√©lectionnez le **mod√®le gpt-4o-mini** dans la liste des mod√®les.
    Vous pouvez utiliser la barre de recherche pour le trouver.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image11.png)

3.  Sur la page des d√©tails du mod√®le, s√©lectionnez **Deploy**.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image12.png)

4.  Conservez le **Deployment name** par d√©faut. s√©lectionnez
    **Deploy**. Ou, si le mod√®le n'est pas disponible dans votre r√©gion,
    une autre r√©gion est s√©lectionn√©e pour vous et connect√©e √† votre
    projet. Dans ce cas, s√©lectionnez **Create resource and deploy**

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image13.png)
>
> ![](./media/image14.png)

5.  Apr√®s avoir d√©ploy√© le **gpt-4o-mini**, r√©p√©tez les √©tapes pour
    d√©ployer le mod√®le **+++text-embedding-ada-002+++.**

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image15.png)

### T√¢che 3 : Cr√©er un service Azure AI Search

L'objectif de cette application est d'ancrer les r√©ponses du mod√®le dans
vos donn√©es personnalis√©es. L'index de recherche permet de r√©cup√©rer des
documents pertinents en fonction de la question de l'utilisateur.

Vous avez besoin d'un service Azure AI Search et d'une connexion pour
cr√©er un index de recherche.

1.  Connectez-vous au portail Azure √† l'adresse
    +++<https://portal.azure.com>+++ √† l'aide des informations
    d'identification de connexion Azure.

2.  Dans la barre de recherche de la page d'accueil, recherchez **+++AI
    search+++** et s√©lectionnez-le.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image16.png)

3.  Cliquez sur +**Create** et remplissez les d√©tails suivants.

> ![](./media/image17.png)

4.  Entrez les d√©tails ci-dessous et s√©lectionnez **Review + create**

- Subscription‚Äì S√©lectionnez l'abonnement qui vous a √©t√© attribu√©

- Resource Group ‚Äì S√©lectionnez le Resource Group qui vous est attribu√©

- Service name ‚Äì Entrez +++**aisearch\<Lab instance ID\>**+++ en
  rempla√ßant Lab instance id par l'ID de votre VM.

- R√©gion - S√©lectionnez Sweden, Central or East US 2(nous utilisons Est
  US 2 ici)

- Niveau tarifaire ‚Äì S√©lectionnez **Standard**

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image18.png)

5.  V√©rifiez les d√©tails et s√©lectionnez **Create**

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image19.png)

6.  Attendez que le d√©ploiement r√©ussisse comme dans la capture d'√©cran
    ci-dessous avant de passer √† l'√©tape suivante.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image20.png)

### T√¢che 4 : Connecter Azure AI Search √† votre projet

Dans le portail Azure AI Foundry, recherchez une ressource connect√©e √†
Azure AI Search.

1.  Dans votre projet dans Azure AI Foundry, s√©lectionnez **Management
    center** dans le volet gauche.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image21.png)

2.  Dans la section **Connected resources**, s√©lectionnez **New
    connection**, puis **Azure AI Search**.

> ![](./media/image22.png)
>
> ![](./media/image23.png)

3.  S√©lectionnez **API key** sous **Authentication** et s√©lectionnez
    **Add connection**

> ![Une capture d'√©cran d'un moteur de recherche Description g√©n√©r√©e
> automatiquement](./media/image24.png)
>
> ![Une capture d'√©cran d'un moteur de recherche Description g√©n√©r√©e
> automatiquement](./media/image25.png)
>
> ![](./media/image26.png)

### T√¢che 5 : Installer Azure CLI et se connecter

Vous installez Azure CLI et vous vous connectez √† partir de votre
environnement de d√©veloppement local, afin de pouvoir utiliser vos
informations d'identification utilisateur pour appeler le service Azure
OpenAI.

1.  Recherchez **+++PowerShell+++** dans la barre de recherche Windows
    et ouvrez-le en mode administrateur.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image27.png)

2.  Ouvrez windows Power Shell et collez la commande ci-dessous et
    ex√©cutez-la.

> $progressPreference = 'silentlyContinue'
>
> Write-Host "Installing WinGet PowerShell module from PSGallery..."
>
> Install-PackageProvider -Name NuGet -Force | Out-Null
>
> Install-Module -Name Microsoft.WinGet.Client -Force -Repository
> PSGallery | Out-Null
>
> Write-Host "Using Repair-WinGetPackageManager cmdlet to bootstrap
> WinGet..."
>
> Repair-WinGetPackageManager
>
> Write-Host "Done."

3.  Installez Azure CLI √† partir de votre terminal √† l'aide de la
    commande suivante :

winget install -e --id Microsoft.AzureCLI

S√©lectionnez **Y** lorsque vous √™tes invit√© √† accepter.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image28.png)

![](./media/image29.png)

![](./media/image30.png)

4.  Apr√®s avoir install√© Azure CLI, connectez-vous √† l'aide de la
    commande az login et connectez-vous √† l'aide du navigateur :

+++Az login+++

S√©lectionnez **Work or school account** et cliquez sur **Continue**

![Une capture d'√©cran d'un √©cran d'ordinateur Description g√©n√©r√©e
automatiquement](./media/image31.png)

5.  Connectez-vous √† l'aide d‚Äô **Azure login credentials**.

![Une capture d'√©cran d'ordinateur d'un programme Description g√©n√©r√©e
automatiquement](./media/image32.png)

6.  Entrez **1** pour l'invite **Select a subscription** et cliquez sur
    **Enter**

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image33.png)

### T√¢che 6 : Cr√©er un nouvel environnement Python

Tout d'abord, vous devez cr√©er un nouvel environnement Python √† utiliser
pour installer le package dont vous avez besoin pour ce tutoriel.
N'installez PAS de packages dans votre installation python globale. Vous
devez toujours utiliser un environnement virtuel ou conda lors de
l'installation de packages python, sinon vous pouvez interrompre votre
installation globale de Python.

**Cr√©ation d'un environnement virtuel**

1.  √Ä partir de votre Power Shell, acc√©dez √† **C¬†:\Users\Admin** en
    ex√©cutant les commandes ci-dessous.

+++cd\\++

+++cd Users\Admin+++

2.  Cr√©ez un dossier avec le nom de votre projet, **RAGproj\<Lab
    instance id\>, by entering the following command in your
    powershell.**

**Remarque :** Remplacez \<Nom du projet\> par le nom de votre projet
dans la commande ci-dessous et ex√©cutez-le.

+++**mkdir \<Project name\>**+++

![Un √©cran d'ordinateur avec du texte blanc et vert Description g√©n√©r√©e
automatiquement](./media/image34.png)

3.  Dans votre terminal, entrez la commande suivante pour acc√©der au
    nouvel emplacement du dossier

+++cd **\<Project name\>+++**

Remplacez \<**Project name**\> par le nom du dossier que vous avez cr√©√©
√† l'√©tape pr√©c√©dente.

![Un √©cran bleu avec du texte blanc Description g√©n√©r√©e
automatiquement](./media/image35.png)

4.  Cr√©ez un environnement virtuel √† l'aide des commandes suivantes

+++py -3 -m venv .venv+++

+++.venv\scripts\activer+++

> ![Une capture d'√©cran d'ordinateur d'un code Description g√©n√©r√©e
> automatiquement](./media/image36.png)
>
> L'activation de l'environnement Python signifie que lorsque vous
> ex√©cutez python ou pip √† partir de la ligne de commande, vous utilisez
> ensuite l'interpr√©teur Python contenu dans le dossier .venv de votre
> application.

5.  Ouvrez **VS Code**. S√©lectionnez **File-\> Open folder**, puis
    s√©lectionnez le dossier **RAGproject** que nous avons cr√©√© dans les
    √©tapes pr√©c√©dentes.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image37.png)

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image38.png)

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image39.png)

### T√¢che 7 : Installer les packages

Installez azure-ai-projects (pr√©version) et azure-ai-inference
(pr√©version), ainsi que d'autres packages requis.

1.  Cr√©ez un fichier nomm√© **+++requirements.txt+++** dans votre dossier
    **Project** et ajoutez les packages suivants au fichier :

> azure-ai-projects
>
> azure-ai-inference\[prompts\]
>
> azure-identity
>
> azure-search-documents
>
> pandas
>
> python-dotenv
>
> opentelemetry-api

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image40.png)

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image41.png)

2.  Dans la barre de navigation sup√©rieure, cliquez sur fichier et
    **save all.**

3.  Faites un clic droit sur le requirements.txt et s√©lectionnez **Open
    in Integrated Terminal**

![](./media/image42.png)

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image43.png)

4.  Ex√©cutez la commande suivante pour acc√©der √† l'environnement virtuel

py -3 -m venv .venv

.venv\scripts\activate

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image44.png)

5.  Ex√©cutez la commande +++az login+++ et connectez-vous avec vos Azure
    login credentials. S√©lectionnez **1** pour s√©lectionner
    l'abonnement.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image45.png)

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image46.png)

6.  Pour installer les packages requis, ex√©cutez le code suivant.

+++pip install -r requirements.txt+++

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image47.png)

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image48.png)

> **Remarque :** Si vous recevez une notification de nouvelle version de
> pip, ex√©cutez les commandes ci-dessous pour mettre √† jour pip
>
> +++pip install -r requirements.txt+++

+++python.exe -m pip install --upgrade pip+++

> ![Une capture d'√©cran d'un programme informatique Description g√©n√©r√©e
> automatiquement](./media/image49.png)

### T√¢che 8 : Cr√©er un script d'assistance

1.  Cr√©ez un nouveau dossier nomm√© **src**. En ex√©cutant la commande
    suivante dans le terminal.

mkdir src

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image50.png)

2.  Cr√©ez un nouveau fichier dans le dossier **src** et nommez-le
    **+++config.py+++**

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image51.png)

3.  Ajoutez le code suivant √† **config.py** et enregistrez-le.

\# ruff: noqa: ANN201, ANN001

import os

import sys

import pathlib

import logging

from azure.identity import DefaultAzureCredential

from azure.ai.projects import AIProjectClient

from azure.ai.inference.tracing import AIInferenceInstrumentor

\# load environment variables from the .env file

from dotenv import load_dotenv

load_dotenv()

\# Set "./assets" as the path where assets are stored, resolving the
absolute path:

ASSET_PATH = pathlib.Path(\_\_file\_\_).parent.resolve() / "assets"

\# Configure an root app logger that prints info level logs to stdout

logger = logging.getLogger("app")

logger.setLevel(logging.INFO)

logger.addHandler(logging.StreamHandler(stream=sys.stdout))

\# Returns a module-specific logger, inheriting from the root app logger

def get_logger(module_name):

return logging.getLogger(f"app.{module_name}")

\# Enable instrumentation and logging of telemetry to the project

def enable_telemetry(log_to_project: bool = False):

AIInferenceInstrumentor().instrument()

\# enable logging message contents

os.environ\["AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED"\] = "true"

if log_to_project:

from azure.monitor.opentelemetry import configure_azure_monitor

project = AIProjectClient.from_connection_string(

conn_str=os.environ\["AIPROJECT_CONNECTION_STRING"\],
credential=DefaultAzureCredential()

)

tracing_link =
f"https://ai.azure.com/tracing?wsid=/subscriptions/{project.scope\['subscription_id'\]}/resourceGroups/{project.scope\['resource_group_name'\]}/providers/Microsoft.MachineLearningServices/workspaces/{project.scope\['project_name'\]}"

application_insights_connection_string =
project.telemetry.get_connection_string()

if not application_insights_connection_string:

logger.warning(

"No application insights configured, telemetry will not be logged to
project. Add application insights at:"

)

logger.warning(tracing_link)

return

configure_azure_monitor(connection_string=application_insights_connection_string)

logger.info("Enabled telemetry logging to project, view traces at:")

logger.info(tracing_link)

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image52.png)

**Remarque** : ce script de fichier config.py nouvellement cr√©√© sera
utilis√© dans l'exercice suivant.

### T√¢che 9 : Configurer les variables d'environnement

Votre cha√Æne de connexion de projet est requise pour appeler le service
Azure OpenAI √† partir de votre code. Dans ce guide de d√©marrage rapide,
vous allez enregistrer cette valeur dans un fichier .env, qui contient
des variables d'environnement que votre application peut lire.

1.  Cr√©ez un nouveau fichier +++**.env**+++ dans le r√©pertoire **src**
    et collez le code suivant :

Remplacez la **\<your-connection-string\>** par la valeur de la cha√Æne
de connexion du projet enregistr√©e dans le bloc-notes dans la t√¢che 1.

AIPROJECT_CONNECTION_STRING=\<your-connection-string\>

AISEARCH_INDEX_NAME="example-index"

EMBEDDINGS_MODEL="text-embedding-ada-002"

INTENT_MAPPING_MODEL="gpt-4o-mini"

CHAT_MODEL="gpt-4o-mini"

EVALUATION_MODEL="gpt-4o-mini"

![](./media/image53.png)

**Remarque** : Votre cha√Æne de connexion se trouve dans la page
d'accueil du projet Azure AI Foundry sous **Overview**

## Exercice 2 : Cr√©er une application de r√©cup√©ration des connaissances (RAG) personnalis√©e avec le SDK Azure AI Foundry

### T√¢che 1 : Cr√©er des exemples de donn√©es pour votre application de chat

L'objectif de cette application bas√©e sur RAG est d'ancrer les r√©ponses
du mod√®le dans vos donn√©es personnalis√©es. Vous utilisez un index Azure
AI Search qui stocke des donn√©es vectoris√©es √† partir du mod√®le
d'int√©gration. L'index de recherche permet de r√©cup√©rer des documents
pertinents en fonction de la question de l'utilisateur.

1.  √Ä partir de votre configuration VS Code qui est ouverte, cr√©ez un
    dossier nomm√© +++assets+++ sous le dossier **src**.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image54.png)

2.  Copiez **products.csv** fichier √† partir de **C¬†:\LabFiles** et
    collez-le dans le dossier racine du **Project**.

Remarque : Cela doit √™tre fait dans l'explorateur de fichiers, puis il
sera refl√©t√© dans le VS Code.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image55.png)

3.  Acc√©dez √† **File** dans la barre de navigation sup√©rieure et cliquez
    sur **Save all.**

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image56.png)

### T√¢che 2 : Cr√©er un index de recherche

> L'index de recherche est utilis√© pour stocker les donn√©es vectoris√©es
> du mod√®le d'embeddings. L'index de recherche permet de r√©cup√©rer des
> documents pertinents en fonction de la question de l'utilisateur.

1.  Dans VS code, cr√©ez un fichier nomm√©
    **+++create_search_index.py+++** dans votre dossier src
    (c'est-√†-dire le m√™me r√©pertoire o√π vous avez plac√© votre dossier
    **assets**, et non √† l'int√©rieur du dossier **assets**).

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image57.png)

2.  Ouvrez le fichier cr√©√©, **create_search_index.py** fichier et
    ajoutez le code suivant pour importer les biblioth√®ques requises,
    cr√©er un client de projet et configurer certains param√®tres :

> import os
>
> from azure.ai.projects import AIProjectClient
>
> from azure.ai.projects.models import ConnectionType
>
> from azure.identity import DefaultAzureCredential
>
> from azure.core.credentials import AzureKeyCredential
>
> from azure.search.documents import SearchClient
>
> from azure.search.documents.indexes import SearchIndexClient
>
> from config import get_logger
>
> \# initialize logging object
>
> logger = get_logger(\_\_name\_\_)
>
> \# create a project client using environment variables loaded from the
> .env file
>
> project = AIProjectClient.from_connection_string(
>
> conn_str=os.environ\["AIPROJECT_CONNECTION_STRING"\],
> credential=DefaultAzureCredential()
>
> )
>
> \# create a vector embeddings client that will be used to generate
> vector embeddings
>
> embeddings = project.inference.get_embeddings_client()
>
> \# use the project client to get the default search connection
>
> search_connection = project.connections.get_default(
>
> connection_type=ConnectionType.AZURE_AI_SEARCH,
> include_credentials=True
>
> )
>
> \# Create a search index client using the search connection
>
> \# This client will be used to create and delete search indexes
>
> index_client = SearchIndexClient(
>
> endpoint=search_connection.endpoint_url,
> credential=AzureKeyCredential(key=search_connection.key)
>
> )
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image58.png)

3.  Ajoutez maintenant la fonction √† la fin de la
    **create_search_index.py** pour d√©finir un index de recherche :

> import pandas as pd
>
> from azure.search.documents.indexes.models import (
>
> SemanticSearch,
>
> SearchField,
>
> SimpleField,
>
> SearchableField,
>
> SearchFieldDataType,
>
> SemanticConfiguration,
>
> SemanticPrioritizedFields,
>
> SemanticField,
>
> VectorSearch,
>
> HnswAlgorithmConfiguration,
>
> VectorSearchAlgorithmKind,
>
> HnswParameters,
>
> VectorSearchAlgorithmMetric,
>
> ExhaustiveKnnAlgorithmConfiguration,
>
> ExhaustiveKnnParameters,
>
> VectorSearchProfile,
>
> SearchIndex,
>
> )
>
> def create_index_definition(index_name: str, model: str) -\>
> SearchIndex:
>
> dimensions = 1536 \# text-embedding-ada-002
>
> if model == "text-embedding-3-large":
>
> dimensions = 3072
>
> \# The fields we want to index. The "embedding" field is a vector
> field that will
>
> \# be used for vector search.
>
> fields = \[
>
> SimpleField(name="id", type=SearchFieldDataType.String, key=True),
>
> SearchableField(name="content", type=SearchFieldDataType.String),
>
> SimpleField(name="filepath", type=SearchFieldDataType.String),
>
> SearchableField(name="title", type=SearchFieldDataType.String),
>
> SimpleField(name="url", type=SearchFieldDataType.String),
>
> SearchField(
>
> name="contentVector",
>
> type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
>
> searchable=True,
>
> \# Size of the vector created by the text-embedding-ada-002 model.
>
> vector_search_dimensions=dimensions,
>
> vector_search_profile_name="myHnswProfile",
>
> ),
>
> \]
>
> \# The "content" field should be prioritized for semantic ranking.
>
> semantic_config = SemanticConfiguration(
>
> name="default",
>
> prioritized_fields=SemanticPrioritizedFields(
>
> title_field=SemanticField(field_name="title"),
>
> keywords_fields=\[\],
>
> content_fields=\[SemanticField(field_name="content")\],
>
> ),
>
> )
>
> \# For vector search, we want to use the HNSW (Hierarchical Navigable
> Small World)
>
> \# algorithm (a type of approximate nearest neighbor search algorithm)
> with cosine
>
> \# distance.
>
> vector_search = VectorSearch(
>
> algorithms=\[
>
> HnswAlgorithmConfiguration(
>
> name="myHnsw",
>
> kind=VectorSearchAlgorithmKind.HNSW,
>
> parameters=HnswParameters(
>
> m=4,
>
> ef_construction=1000,
>
> ef_search=1000,
>
> metric=VectorSearchAlgorithmMetric.COSINE,
>
> ),
>
> ),
>
> ExhaustiveKnnAlgorithmConfiguration(
>
> name="myExhaustiveKnn",
>
> kind=VectorSearchAlgorithmKind.EXHAUSTIVE_KNN,
>
> parameters=ExhaustiveKnnParameters(metric=VectorSearchAlgorithmMetric.COSINE),
>
> ),
>
> \],
>
> profiles=\[
>
> VectorSearchProfile(
>
> name="myHnswProfile",
>
> algorithm_configuration_name="myHnsw",
>
> ),
>
> VectorSearchProfile(
>
> name="myExhaustiveKnnProfile",
>
> algorithm_configuration_name="myExhaustiveKnn",
>
> ),
>
> \],
>
> )
>
> \# Create the semantic settings with the configuration
>
> semantic_search = SemanticSearch(configurations=\[semantic_config\])
>
> \# Create the search index definition
>
> return SearchIndex(
>
> name=index_name,
>
> fields=fields,
>
> semantic_search=semantic_search,
>
> vector_search=vector_search,
>
> )![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image59.png)

4.  Ajoutez maintenant la fonction dans create_search_index.py pour
    cr√©er la fonction permettant d'ajouter un fichier csv √† l'index :

> \# define a function for indexing a csv file, that adds each row as a
> document
>
> \# and generates vector embeddings for the specified content_column
>
> def create_docs_from_csv(path: str, content_column: str, model: str)
> -\> list\[dict\[str, any\]\]:
>
> products = pd.read_csv(path)
>
> items = \[\]
>
> for product in products.to_dict("records"):
>
> content = product\[content_column\]
>
> id = str(product\["id"\])
>
> title = product\["name"\]
>
> url = f"/products/{title.lower().replace(' ', '-')}"
>
> emb = embeddings.embed(input=content, model=model)
>
> rec = {
>
> "id": id,
>
> "content": content,
>
> "filepath": f"{title.lower().replace(' ', '-')}",
>
> "title": title,
>
> "url": url,
>
> "contentVector": emb.data\[0\].embedding,
>
> }
>
> items.append(rec)
>
> return items
>
> def create_index_from_csv(index_name, csv_file):
>
> \# If a search index already exists, delete it:
>
> try:
>
> index_definition = index_client.get_index(index_name)
>
> index_client.delete_index(index_name)
>
> logger.info(f"üóëÔ∏è Found existing index named '{index_name}', and
> deleted it")
>
> except Exception:
>
> pass
>
> \# create an empty search index
>
> index_definition = create_index_definition(index_name,
> model=os.environ\["EMBEDDINGS_MODEL"\])
>
> index_client.create_index(index_definition)
>
> \# create documents from the products.csv file, generating vector
> embeddings for the "description" column
>
> docs = create_docs_from_csv(path=csv_file,
> content_column="description", model=os.environ\["EMBEDDINGS_MODEL"\])
>
> \# Add the documents to the index using the Azure AI Search client
>
> search_client = SearchClient(
>
> endpoint=search_connection.endpoint_url,
>
> index_name=index_name,
>
> credential=AzureKeyCredential(key=search_connection.key),
>
> )
>
> search_client.upload_documents(docs)
>
> logger.info(f"‚ûï Uploaded {len(docs)} documents to '{index_name}'
> index")
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image60.png)

5.  Enfin, ajoutez les fonctions ci-dessous dans create_search_index.py
    pour cr√©er l'index et l'enregistrer dans le projet cloud. Apr√®s
    avoir ajout√© le code, allez dans Fichiers dans la barre sup√©rieure
    et cliquez sur **Save all.**

> if \_\_name\_\_ == "\_\_main\_\_":
>
> import argparse
>
> parser = argparse.ArgumentParser()
>
> parser.add_argument(
>
> "--index-name",
>
> type=str,
>
> help="index name to use when creating the AI Search index",
>
> default=os.environ\["AISEARCH_INDEX_NAME"\],
>
> )
>
> parser.add_argument(
>
> "--csv-file", type=str, help="path to data for creating search index",
> default="assets/products.csv"
>
> )
>
> args = parser.parse_args()
>
> index_name = args.index_name
>
> csv_file = args.csv_file
>
> create_index_from_csv(index_name, csv_file)
>
> ![](./media/image61.png)

6.  Faites un clic droit sur le **create_search_index.py** et
    s√©lectionnez l'option **Open in integrated terminal**

![](./media/image62.png)

7.  √Ä partir de votre terminal, connectez-vous √† vos identifiants de
    connexion Azure et suivez les instructions d'authentification de
    votre compte :

> +++az login+++
>
> ![](./media/image63.png)
>
> ![](./media/image64.png)

8.  Ex√©cutez le code pour g√©n√©rer votre index localement et
    l'enregistrer dans le projet cloud :

> +++python create_search_index.py+++
>
> ![](./media/image65.png)

9.  Une fois le script ex√©cut√©, vous pouvez afficher votre index
    nouvellement cr√©√© √† partir du portail Azure.

10. Acc√©dez √† l‚Äôespace attribu√© **Resource Group -\> Your search service
    created(aisearchLabinstanceID) -\> Search management -\> Indexes**.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image66.png)

11. Si vous ex√©cutez √† nouveau le script avec le m√™me nom d'index, il
    cr√©e une nouvelle version du m√™me index.

### T√¢che 3 : Obtenir les documents du produit

> Ensuite, vous cr√©ez un script pour obtenir des documents de produit √†
> partir de l'index de recherche. Le script interroge l'index de
> recherche pour trouver les documents qui correspondent √† la question
> d'un utilisateur.
>
> **Cr√©er un script pour obtenir des documents sur les produits**
>
> Lorsque le chat re√ßoit une demande, il recherche dans vos donn√©es pour
> trouver des informations pertinentes. Ce script utilise le Kit de
> d√©veloppement logiciel (SDK) Azure AI pour interroger l'index de
> recherche des documents qui correspondent √† la question d'un
> utilisateur. Il renvoie ensuite les documents √† l'application de chat.

1.  √Ä partir de VS Code, cr√©ez un fichier nomm√©
    **+++get_product_documents.py+++** dans le dossier **src**.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image67.png)

2.  Copiez et collez le code suivant dans le fichier. Commencez par le
    code pour importer les biblioth√®ques requises, cr√©er un client de
    projet et configurer les param√®tres.

> import os
>
> from pathlib import Path
>
> from opentelemetry import trace
>
> from azure.ai.projects import AIProjectClient
>
> from azure.ai.projects.models import ConnectionType
>
> from azure.identity import DefaultAzureCredential
>
> from azure.core.credentials import AzureKeyCredential
>
> from azure.search.documents import SearchClient
>
> from config import ASSET_PATH, get_logger
>
> \# initialize logging and tracing objects
>
> logger = get_logger(\_\_name\_\_)
>
> tracer = trace.get_tracer(\_\_name\_\_)
>
> \# create a project client using environment variables loaded from the
> .env file
>
> project = AIProjectClient.from_connection_string(
>
> conn_str=os.environ\["AIPROJECT_CONNECTION_STRING"\],
> credential=DefaultAzureCredential()
>
> )
>
> \# create a vector embeddings client that will be used to generate
> vector embeddings
>
> chat = project.inference.get_chat_completions_client()
>
> embeddings = project.inference.get_embeddings_client()
>
> \# use the project client to get the default search connection
>
> search_connection = project.connections.get_default(
>
> connection_type=ConnectionType.AZURE_AI_SEARCH,
> include_credentials=True
>
> )
>
> \# Create a search index client using the search connection
>
> \# This client will be used to create and delete search indexes
>
> search_client = SearchClient(
>
> index_name=os.environ\["AISEARCH_INDEX_NAME"\],
>
> endpoint=search_connection.endpoint_url,
>
> credential=AzureKeyCredential(key=search_connection.key),
>
> )

3.  Ajoutez la fonction dans get_product-documents.py pour **get product
    documents**

> from azure.ai.inference.prompts import PromptTemplate
>
> from azure.search.documents.models import VectorizedQuery
>
> @tracer.start_as_current_span(name="get_product_documents")
>
> def get_product_documents(messages: list, context: dict = None) -\>
> dict:
>
> if context is None:
>
> context = {}
>
> overrides = context.get("overrides", {})
>
> top = overrides.get("top", 5)
>
> \# generate a search query from the chat messages
>
> intent_prompty = PromptTemplate.from_prompty(Path(ASSET_PATH) /
> "intent_mapping.prompty")
>
> intent_mapping_response = chat.complete(
>
> model=os.environ\["INTENT_MAPPING_MODEL"\],
>
> messages=intent_prompty.create_messages(conversation=messages),
>
> \*\*intent_prompty.parameters,
>
> )
>
> search_query = intent_mapping_response.choices\[0\].message.content
>
> logger.debug(f"üß† Intent mapping: {search_query}")
>
> \# generate a vector representation of the search query
>
> embedding = embeddings.embed(model=os.environ\["EMBEDDINGS_MODEL"\],
> input=search_query)
>
> search_vector = embedding.data\[0\].embedding
>
> \# search the index for products matching the search query
>
> vector_query = VectorizedQuery(vector=search_vector,
> k_nearest_neighbors=top, fields="contentVector")
>
> search_results = search_client.search(
>
> search_text=search_query, vector_queries=\[vector_query\],
> select=\["id", "content", "filepath", "title", "url"\]
>
> )
>
> documents = \[
>
> {
>
> "id": result\["id"\],
>
> "content": result\["content"\],
>
> "filepath": result\["filepath"\],
>
> "title": result\["title"\],
>
> "url": result\["url"\],
>
> }
>
> for result in search_results
>
> \]
>
> \# add results to the provided context
>
> if "thoughts" not in context:
>
> context\["thoughts"\] = \[\]
>
> \# add thoughts and documents to the context object so it can be
> returned to the caller
>
> context\["thoughts"\].append(
>
> {
>
> "title": "Generated search query",
>
> "description": search_query,
>
> }
>
> )
>
> if "grounding_data" not in context:
>
> context\["grounding_data"\] = \[\]
>
> context\["grounding_data"\].append(documents)
>
> logger.debug(f"üìÑ {len(documents)} documents retrieved: {documents}")
>
> return documents

4.  Enfin, ajoutez du code pour **test the function** lorsque vous
    ex√©cutez directement le script :

> if \_\_name\_\_ == "\_\_main\_\_":
>
> import logging
>
> import argparse
>
> \# set logging level to debug when running this module directly
>
> logger.setLevel(logging.DEBUG)
>
> \# load command line arguments
>
> parser = argparse.ArgumentParser()
>
> parser.add_argument(
>
> "--query",
>
> type=str,
>
> help="Query to use to search product",
>
> default="I need a new tent for 4 people, what would you recommend?",
>
> )
>
> args = parser.parse_args()
>
> query = args.query
>
> result = get_product_documents(messages=\[{"role": "user", "content":
> query}\])
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image68.png)

5.  Cliquez sur **File\> Save all**

![](./media/image69.png)

### T√¢che 4 : Cr√©er un mod√®le d'invite pour le mappage d'intention

> Le script **get_product_documents.py** utilise un mod√®le d'invite pour
> convertir la conversation en requ√™te de recherche. Le mod√®le indique
> comment extraire l'intention de l'utilisateur de la conversation.

1.  Avant d'ex√©cuter le script, cr√©ez le mod√®le d'invite. Cr√©ez un
    fichier nomm√© +++**intent_mapping.prompty**+++ dans votre dossier de
    **assets**:

> ![](./media/image70.png)

4.  Copiez le code suivant dans le fichier intent_mapping_prompty et
    dans la barre sup√©rieure, allez dans Fichiers et cliquez sur **Save
    all.**

> ---
>
> name: Chat Prompt
>
> description: A prompty that extract users query intent based on the
> current_query and chat_history of the conversation
>
> model:
>
> api: chat
>
> configuration:
>
> azure_deployment: gpt-4o
>
> inputs:
>
> conversation:
>
> type: array
>
> ---
>
> system:
>
> \# Instructions
>
> \- You are an AI assistant reading a current user query and
> chat_history.
>
> \- Given the chat_history, and current user's query, infer the user's
> intent expressed in the current user query.
>
> \- Once you infer the intent, respond with a search query that can be
> used to retrieve relevant documents for the current user's query based
> on the intent
>
> \- Be specific in what the user is asking about, but disregard parts
> of the chat history that are not relevant to the user's intent.
>
> \- Provide responses in json format
>
> \# Examples
>
> Example 1:
>
> With a conversation like below:
>
> \`\`\`
>
> \- user: are the trailwalker shoes waterproof?
>
> \- assistant: Yes, the TrailWalker Hiking Shoes are waterproof. They
> are designed with a durable and waterproof construction to withstand
> various terrains and weather conditions.
>
> \- user: how much do they cost?
>
> \`\`\`
>
> Respond with:
>
> {
>
> "intent": "The user wants to know how much the Trailwalker Hiking
> Shoes cost.",
>
> "search_query": "price of Trailwalker Hiking Shoes"
>
> }
>
> Example 2:
>
> With a conversation like below:
>
> \`\`\`
>
> \- user: are the trailwalker shoes waterproof?
>
> \- assistant: Yes, the TrailWalker Hiking Shoes are waterproof. They
> are designed with a durable and waterproof construction to withstand
> various terrains and weather conditions.
>
> \- user: how much do they cost?
>
> \- assistant: The TrailWalker Hiking Shoes are priced at $110.
>
> \- user: do you have waterproof tents?
>
> \- assistant: Yes, we have waterproof tents available. Can you please
> provide more information about the type or size of tent you are
> looking for?
>
> \- user: which is your most waterproof tent?
>
> \- assistant: Our most waterproof tent is the Alpine Explorer Tent. It
> is designed with a waterproof material and has a rainfly with a
> waterproof rating of 3000mm. This tent provides reliable protection
> against rain and moisture.
>
> \- user: how much does it cost?
>
> \`\`\`
>
> Respond with:
>
> {
>
> "intent": "The user would like to know how much the Alpine Explorer
> Tent costs.",
>
> "search_query": "price of Alpine Explorer Tent"
>
> }
>
> user:
>
> Return the search query for the messages in the following
> conversation:
>
> {{#conversation}}
>
> \- {{role}}: {{content}}
>
> {{/conversation}}
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image71.png)

### T√¢che 5 : Tester le script d'extraction de documents produit

1.  Maintenant que vous disposez √† la fois du script et du mod√®le,
    ex√©cutez le script pour tester les documents renvoy√©s par l'index de
    recherche √† partir d'une requ√™te. √Ä partir de la fen√™tre du
    terminal, ex√©cutez

> +++python get_product_documents.py --query "I need a new tent for 4
> people, what would you recommend?"+++
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image72.png)

### T√¢che 6 : D√©velopper un code de r√©cup√©ration de connaissances personnalis√© (RAG)

> Ensuite, vous cr√©ez du code personnalis√© pour ajouter des
> fonctionnalit√©s de g√©n√©ration augment√©e de r√©cup√©ration (RAG) √† une
> application de chat de base.
>
> **Cr√©er un script de chat avec les fonctionnalit√©s RAG**

1.  Dans votre dossier **src**, cr√©ez un nouveau fichier appel√©
    **+++chat_with_products.py+++.** Ce script r√©cup√®re les documents du
    produit et g√©n√®re une r√©ponse √† la question d'un utilisateur.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image73.png)

2.  Ajoutez le code pour importer les biblioth√®ques requises, cr√©er un
    client de projet et configurer les param√®tres :

> import os
>
> from pathlib import Path
>
> from opentelemetry import trace
>
> from azure.ai.projects import AIProjectClient
>
> from azure.identity import DefaultAzureCredential
>
> from config import ASSET_PATH, get_logger, enable_telemetry
>
> from get_product_documents import get_product_documents
>
> \# initialize logging and tracing objects
>
> logger = get_logger(\_\_name\_\_)
>
> tracer = trace.get_tracer(\_\_name\_\_)
>
> \# create a project client using environment variables loaded from the
> .env file
>
> project = AIProjectClient.from_connection_string(
>
> conn_str=os.environ\["AIPROJECT_CONNECTION_STRING"\],
> credential=DefaultAzureCredential()
>
> )
>
> \# create a chat client we can use for testing
>
> chat = project.inference.get_chat_completions_client()
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image74.png)

3.  Ajoutez le code √† la fin de chat_with_products.py pour cr√©er la
    fonction de chat qui utilise les fonctionnalit√©s RAG.

> from azure.ai.inference.prompts import PromptTemplate
>
> @tracer.start_as_current_span(name="chat_with_products")
>
> def chat_with_products(messages: list, context: dict = None) -\> dict:
>
> if context is None:
>
> context = {}
>
> documents = get_product_documents(messages, context)
>
> \# do a grounded chat call using the search results
>
> grounded_chat_prompt = PromptTemplate.from_prompty(Path(ASSET_PATH) /
> "grounded_chat.prompty")
>
> system_message =
> grounded_chat_prompt.create_messages(documents=documents,
> context=context)
>
> response = chat.complete(
>
> model=os.environ\["CHAT_MODEL"\],
>
> messages=system_message + messages,
>
> \*\*grounded_chat_prompt.parameters,
>
> )
>
> logger.info(f"üí¨ Response: {response.choices\[0\].message}")
>
> \# Return a chat protocol compliant response
>
> return {"message": response.choices\[0\].message, "context": context}
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image75.png)

4.  Enfin, ajoutez le code pour ex√©cuter la **chat function** puis allez
    dans les fichiers et cliquez sur **Save all**

> if \_\_name\_\_ == "\_\_main\_\_":
>
> import argparse
>
> \# load command line arguments
>
> parser = argparse.ArgumentParser()
>
> parser.add_argument(
>
> "--query",
>
> type=str,
>
> help="Query to use to search product",
>
> default="I need a new tent for 4 people, what would you recommend?",
>
> )
>
> parser.add_argument(
>
> "--enable-telemetry",
>
> action="store_true",
>
> help="Enable sending telemetry back to the project",
>
> )
>
> args = parser.parse_args()
>
> if args.enable_telemetry:
>
> enable_telemetry(True)
>
> \# run chat with products
>
> response = chat_with_products(messages=\[{"role": "user", "content":
> args.query}\])
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image76.png)

### T√¢che 7 : Cr√©er un mod√®le d'invite de chat ancr√©

> Le script **chat_with_products.py** appelle un mod√®le d'invite pour
> g√©n√©rer une r√©ponse √† la question de l'utilisateur. Le mod√®le indique
> comment g√©n√©rer une r√©ponse bas√©e sur la question de l'utilisateur et
> les documents r√©cup√©r√©s. Cr√©ez ce mod√®le maintenant.

1.  Dans votre dossier **assets**, ajoutez le fichier
    +++**grounded_chat.prompty**+++

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image77.png)

2.  Ajoutez le code suivant grounded_chat.prompty.

> ---
>
> name: Chat with documents
>
> description: Uses a chat completions model to respond to queries
> grounded in relevant documents
>
> model:
>
> api: chat
>
> configuration:
>
> azure_deployment: gpt-4o
>
> inputs:
>
> conversation:
>
> type: array
>
> ---
>
> system:
>
> You are an AI assistant helping users with queries related to outdoor
> outdooor/camping gear and clothing.
>
> If the question is not related to outdoor/camping gear and clothing,
> just say 'Sorry, I only can answer queries related to outdoor/camping
> gear and clothing. So, how can I help?'
>
> Don't try to make up any answers.
>
> If the question is related to outdoor/camping gear and clothing but
> vague, ask for clarifying questions instead of referencing documents.
> If the question is general, for example it uses "it" or "they", ask
> the user to specify what product they are asking about.
>
> Use the following pieces of context to answer the questions about
> outdoor/camping gear and clothing as completely, correctly, and
> concisely as possible.
>
> Do not add documentation reference in the response.
>
> \# Documents
>
> {{#documents}}
>
> \## Document {{id}}: {{title}}
>
> {{content}}
>
> {{/documents}}
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image78.png)

3.  Cliquez sur **File\> Save all**

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image79.png)

### T√¢che 8 : Ex√©cuter le script de chat avec les capacit√©s RAG

1.  Maintenant que vous disposez √† la fois du script et du mod√®le,
    ex√©cutez le script pour tester votre application de chat avec les
    fonctionnalit√©s RAG :

> +++python chat_with_products.py --query "I need a new tent for 4
> people, what would you recommend?"+++
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image80.png)

### T√¢che 9 : Ajouter la journalisation des donn√©es de t√©l√©m√©trie

1.  Dans le portail Azure, s√©lectionnez **Subscription** , puis
    **Resource providers** sous **Settings** dans le volet de navigation
    de gauche.

2.  Recherchez et s√©lectionnez +++**Microsoft.OperationalInsights**+++
    et cliquez sur les trois points de ce fournisseur de ressources et
    s√©lectionnez **Register.**

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image81.png)

3.  Suivez la m√™me proc√©dure pour enregistrer +++microsoft.insights+++

4.  Attendez un message de r√©ussite sur l'inscription avant de passer √†
    l'√©tape suivante.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image82.png)

5.  √Ä partir de votre projet dans Azure AI Foundry, s√©lectionnez
    **Tracing** sous **Access and improve** dans le volet gauche.
    S√©lectionnez **Create new.**

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image83.png)
>
> ![Une capture d'√©cran d'un √©cran d'ordinateur Description g√©n√©r√©e
> automatiquement](./media/image84.png)

6.  Assurez-vous que la ressource est cr√©√©e.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image85.png)

7.  De retour dans le VS Code, pour activer la journalisation des
    donn√©es de t√©l√©m√©trie dans votre projet, installez
    azure-monitor-opentelemetry.

> +++pip install azure-monitor-opentelemetry+++
>
> ![Une capture d'√©cran d'un programme informatique Description g√©n√©r√©e
> automatiquement](./media/image86.png)

8.  Ajoutez l'indicateur --enable-telemetry lorsque vous utilisez le
    script chat_with_products.py :

> +++python chat_with_products.py --query "I need a new tent for 4
> people, what would you recommend?" --enable-telemetry+++
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image87.png)

## Exercice 3 : √âvaluer l'application de conversation personnalis√©e √† l'aide du Kit de d√©veloppement logiciel (SDK) Azure AI Foundry

### T√¢che 1 : √âvaluer la qualit√© des r√©ponses de l'application de chat

Maintenant que vous savez que votre application de chat r√©pond bien √†
vos requ√™tes, y compris avec l'historique des chats, il est temps
d'√©valuer ses performances sur quelques indicateurs diff√©rents et plus
de donn√©es.

Vous utilisez un √©valuateur avec un jeu de donn√©es d'√©valuation et la
fonction cible get_chat_response(), puis vous √©valuez les r√©sultats de
l'√©valuation.

Une fois que vous avez ex√©cut√© une √©valuation, vous pouvez apporter des
am√©liorations √† votre logique, comme am√©liorer l'invite de votre syst√®me
et observer comment les r√©ponses de l'application de chat changent et
s'am√©liorent.

**Cr√©er un jeu de donn√©es d'√©valuation**

Utilisez le jeu de donn√©es d'√©valuation suivant, qui contient des
exemples de questions et de r√©ponses attendues (v√©rit√©).

1.  Cr√©ez un fichier appel√© +++**chat_eval_data.jsonl**+++ dans votre
    dossier **assets**.

> ![](./media/image88.png)

2.  Collez cet ensemble de donn√©es dans le fichier et **save**

> {"query": "Which tent is the most waterproof?", "truth": "The Alpine
> Explorer Tent has the highest rainfly waterproof rating at 3000m"}
>
> {"query": "Which camping table holds the most weight?", "truth": "The
> Adventure Dining Table has a higher weight capacity than all of the
> other camping tables mentioned"}
>
> {"query": "How much do the TrailWalker Hiking Shoes cost? ", "truth":
> "The Trailewalker Hiking Shoes are priced at $110"}
>
> {"query": "What is the proper care for trailwalker hiking shoes? ",
> "truth": "After each use, remove any dirt or debris by brushing or
> wiping the shoes with a damp cloth."}
>
> {"query": "What brand is TrailMaster tent? ", "truth":
> "OutdoorLiving"}
>
> {"query": "How do I carry the TrailMaster tent around? ", "truth": "
> Carry bag included for convenient storage and transportation"}
>
> {"query": "What is the floor area for Floor Area? ", "truth": "80
> square feet"}
>
> {"query": "What is the material for TrailBlaze Hiking Pants?",
> "truth": "Made of high-quality nylon fabric"}
>
> {"query": "What color does TrailBlaze Hiking Pants come in?", "truth":
> "Khaki"}
>
> {"query": "Can the warrenty for TrailBlaze pants be transfered? ",
> "truth": "The warranty is non-transferable and applies only to the
> original purchaser of the TrailBlaze Hiking Pants. It is valid only
> when the product is purchased from an authorized retailer."}
>
> {"query": "How long are the TrailBlaze pants under warranty for? ",
> "truth": " The TrailBlaze Hiking Pants are backed by a 1-year limited
> warranty from the date of purchase."}
>
> {"query": "What is the material for PowerBurner Camping Stove? ",
> "truth": "Stainless Steel"}
>
> {"query": "Is France in Europe?", "truth": "Sorry, I can only queries
> related to outdoor/camping gear and equipment"}
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image89.png)

### T√¢che 2 : √âvaluer avec des √©valuateurs Azure AI

D√©finissez maintenant un script d'√©valuation qui va :

- G√©n√©rez un wrapper de fonction cible autour de la logique de notre
  application de chat.

- Chargez l'exemple de jeu de donn√©es .jsonl.

- Ex√©cutez l'√©valuation, qui prend la fonction cible et fusionne
  l'ensemble de donn√©es d'√©valuation avec les r√©ponses de l'application
  de conversation.

- G√©n√©rez un ensemble de mesures assist√©es par GPT (pertinence, ancrage
  et coh√©rence) pour √©valuer la qualit√© des r√©ponses de l'application de
  chat.

- Produisez les r√©sultats localement et enregistrez les r√©sultats dans
  le projet cloud.

Le script vous permet d'examiner les r√©sultats localement, en les
sortant dans la ligne de commande et dans un fichier json.

Le script enregistre √©galement les r√©sultats de l'√©valuation dans le
projet cloud afin que vous puissiez comparer les ex√©cutions d'√©valuation
dans l'interface utilisateur.

1.  Cr√©ez un fichier appel√© +++evaluate.py+++ dans le dossier **src**.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image90.png)

2.  Ajoutez le code suivant pour importer les biblioth√®ques requises,
    cr√©er un client de projet et configurer certains param√®tres :

> import os
>
> import pandas as pd
>
> from azure.ai.projects import AIProjectClient
>
> from azure.ai.projects.models import ConnectionType
>
> from azure.ai.evaluation import evaluate, GroundednessEvaluator
>
> from azure.identity import DefaultAzureCredential
>
> from chat_with_products import chat_with_products
>
> \# load environment variables from the .env file at the root of this
> repo
>
> from dotenv import load_dotenv
>
> load_dotenv()
>
> \# create a project client using environment variables loaded from the
> .env file
>
> project = AIProjectClient.from_connection_string(
>
> conn_str=os.environ\["AIPROJECT_CONNECTION_STRING"\],
> credential=DefaultAzureCredential()
>
> )
>
> connection =
> project.connections.get_default(connection_type=ConnectionType.AZURE_OPEN_AI,
> include_credentials=True)
>
> evaluator_model = {
>
> "azure_endpoint": connection.endpoint_url,
>
> "azure_deployment": os.environ\["EVALUATION_MODEL"\],
>
> "api_version": "2024-06-01",
>
> "api_key": connection.key,
>
> }
>
> groundedness = GroundednessEvaluator(evaluator_model)
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image91.png)

3.  Ajoutez du code pour cr√©er une fonction wrapper qui impl√©mente
    l'interface d'√©valuation pour l'√©valuation des requ√™tes et des
    r√©ponses :

> def evaluate_chat_with_products(query):
>
> response = chat_with_products(messages=\[{"role": "user", "content":
> query}\])
>
> return {"response": response\["message"\].content, "context":
> response\["context"\]\["grounding_data"\]}
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image92.png)

4.  Enfin, ajoutez du code pour ex√©cuter l'√©valuation, affichez les
    r√©sultats localement et vous donne un lien vers les r√©sultats de
    l'√©valuation dans le portail AI Foundry.

> \# Evaluate must be called inside of \_\_main\_\_, not on import
>
> if \_\_name\_\_ == "\_\_main\_\_":
>
> from config import ASSET_PATH
>
> \# workaround for multiprocessing issue on linux
>
> from pprint import pprint
>
> from pathlib import Path
>
> import multiprocessing
>
> import contextlib
>
> with contextlib.suppress(RuntimeError):
>
> multiprocessing.set_start_method("spawn", force=True)
>
> \# run evaluation with a dataset and target function, log to the
> project
>
> result = evaluate(
>
> data=Path(ASSET_PATH) / "chat_eval_data.jsonl",
>
> target=evaluate_chat_with_products,
>
> evaluation_name="evaluate_chat_with_products",
>
> evaluators={
>
> "groundedness": groundedness,
>
> },
>
> evaluator_config={
>
> "default": {
>
> "query": {"${data.query}"},
>
> "response": {"${target.response}"},
>
> "context": {"${target.context}"},
>
> }
>
> },
>
> azure_ai_project=project.scope,
>
> output_path="./myevalresults.json",
>
> )
>
> tabular_result = pd.DataFrame(result.get("rows"))
>
> pprint("-----Summarized Metrics-----")
>
> pprint(result\["metrics"\])
>
> pprint("-----Tabular Result-----")
>
> pprint(tabular_result)
>
> pprint(f"View evaluation results in AI Studio:
> {result\['studio_url'\]}")
>
> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image93.png)

5.  Cliquez sur **Save all** sous **File** dans la barre de navigation
    sup√©rieure.

### T√¢che 3 : Configurer le mod√®le d'√©valuation

√âtant donn√© que le script d'√©valuation appelle le mod√®le plusieurs fois,
vous souhaiterez peut-√™tre augmenter le nombre de jetons par minute pour
le mod√®le d'√©valuation.

Initialement, vous avez cr√©√© un fichier **.env** qui sp√©cifie le nom du
mod√®le d'√©valuation, gpt-4o-mini. Essayez d'augmenter la limite de
jetons par minute pour ce mod√®le, si vous avez un quota disponible. Si
vous n'avez pas assez de quota pour augmenter la valeur, ne vous
inqui√©tez pas. Le script est con√ßu pour g√©rer les erreurs de limite.

1.  √Ä partir de votre projet dans le portail Azure AI Foundry,
    s√©lectionnez **Models + endpoints** , puis **gpt-4o-mini**.

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image94.png)

2.  S√©lectionnez **gpt-4o-mini**, cliquez sur **Edit**

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image95.png)

3.  D√©finissez la valeur de la **Tokens per Minutes Rate Limit** sur la
    limite maximale autoris√©e, puis s√©lectionnez **Save and close.**

> ![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
> automatiquement](./media/image96.png)

### T√¢che 4 : Ex√©cuter l'√©valuation 

1.  Dans Azure AI Foundry, s√©lectionnez **Evaluations** dans le volet
    gauche, puis s√©lectionnez **+ New Evaluation**

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image97.png)

2.  S√©lectionnez **Dataset**.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image98.png)

3.  Acceptez les valeurs par d√©faut dans la page Informations de base et
    cliquez sur **Next.**

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image99.png)

4.  S√©lectionnez **Add youir dataset -\> Upload file** le fichier et
    chargez le fichier **chat_eval_data.jsonl** que nous avons cr√©√© dans
    le dossier des **assets** et cliquez sur **Next**.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image100.png)

5.  S√©lectionnez les **Metrics** sous AI quality and Risk and safety
    metrics.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image101.png)

![Une capture d'√©cran d'une enqu√™te Description g√©n√©r√©e
automatiquement](./media/image102.png)

6.  S√©lectionnez les types de source de donn√©es comme dans la capture
    d'√©cran ci-dessous et cliquez sur **Next**

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image103.png)

7.  S√©lectionnez **Submit** pour soumettre l'√©valuation.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image104.png)

8.  Une fois l'√©valuation termin√©e, explorez les r√©sultats.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image105.png)

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image106.png)

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image107.png)

## Exercice 4 : Supprimer les ressources

1.  Dans la page d'accueil du portail Azure, s√©lectionnez le Resource
    Group attribu√©. S√©lectionnez toutes les ressources sous le Resource
    Group , puis s√©lectionnez Delete.

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image108.png)

2.  Entrez **+++delete+++** et cliquez sur le bouton **Delete** pour
    confirmer la suppression. Cliquez sur **Delete** dans la bo√Æte de
    dialogue de confirmation Delete

![Une capture d'√©cran d'un ordinateur Description g√©n√©r√©e
automatiquement](./media/image109.png)

3.  Confirmez la suppression de toutes les ressources avec un message de
    r√©ussite.

![Une capture d'√©cran d'un √©cran d'ordinateur Description g√©n√©r√©e
automatiquement](./media/image110.png)

> **R√©sum√©:**
>
> Dans ce laboratoire nous avons appris √† cr√©er, √©valuer et d√©ployer une
> application bas√©e sur RAG.
